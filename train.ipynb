{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPu6gMlijym3QIaKgiNnYPy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"m6kC_nJ52fOQ","colab_type":"text"},"source":["#드라이브 마운트"]},{"cell_type":"code","metadata":{"id":"wNs-Ty8W1pv2","colab_type":"code","outputId":"bcaabdd9-93df-4240-c8b4-e35dde860155","executionInfo":{"status":"ok","timestamp":1582062185204,"user_tz":420,"elapsed":1514,"user":{"displayName":"한요섭","photoUrl":"https://lh5.googleusercontent.com/-YFCq7U3ZRkA/AAAAAAAAAAI/AAAAAAAARHc/gXM5cCKzru0/s64/photo.jpg","userId":"13321053678363808287"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cvnaQoOB2zb_","colab_type":"text"},"source":["#라이브러리 추가하기"]},{"cell_type":"code","metadata":{"id":"-3cLK0pq2FTO","colab_type":"code","colab":{}},"source":["import os\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","\n","from torchvision import transforms, datasets"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"03q8gEWY3EYb","colab_type":"text"},"source":["#트레이닝 파라메터 설정하기"]},{"cell_type":"code","metadata":{"id":"aj5hpOAY3ByJ","colab_type":"code","outputId":"068ad1be-c9ab-45ae-c744-60c217fc90ac","executionInfo":{"status":"ok","timestamp":1582062501544,"user_tz":420,"elapsed":1819,"user":{"displayName":"한요섭","photoUrl":"https://lh5.googleusercontent.com/-YFCq7U3ZRkA/AAAAAAAAAAI/AAAAAAAARHc/gXM5cCKzru0/s64/photo.jpg","userId":"13321053678363808287"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["lr = 1e-3\n","batch_size = 64\n","num_epoch = 10\n","\n","num_freq = 100\n","\n","ckpt_dir = './drive/My Drive/YouTube/001-pytorch-mnist/checkpoint'\n","log_dir = './drive/My Drive/YouTube/001-pytorch-mnist/mnist/log'\n","data_dir = './drive/My Drive/YouTube/001-pytorch-mnist/mnist/data'\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","print(device)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["cuda\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3H_sLuQC3f4y","colab_type":"text"},"source":["#네트워크 구축하기"]},{"cell_type":"code","metadata":{"id":"jJtKk8fN3Vd0","colab_type":"code","colab":{}},"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5, stride=1, padding=0, bias=True)\n","        self.pool1 = nn.MaxPool2d(kernel_size=2)\n","        self.relu1 = nn.ReLU()\n","\n","        self.conv2 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=5, stride=1, padding=0, bias=True)\n","        self.drop2 = nn.Dropout2d(p=0.5)\n","        self.pool2 = nn.MaxPool2d(kernel_size=2)\n","        self.relu2 = nn.ReLU()\n","\n","        self.fc1 = nn.Linear(in_features=320, out_features=50, bias=True)\n","        self.relu1_fc1 = nn.ReLU()\n","        self.drop1_fc1 = nn.Dropout2d(p=0.5)\n","\n","        self.fc2 = nn.Linear(in_features=50, out_features=10, bias=True)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.pool1(x)\n","        x = self.relu1(x)\n","\n","        x = self.conv2(x)\n","        x = self.drop2(x)\n","        x = self.pool2(x)\n","        x = self.relu2(x)\n","\n","        x = x.view(-1, 320)\n","\n","        x = self.fc1(x)\n","        x = self.relu1_fc1(x)\n","        x = self.drop1_fc1(x)\n","\n","        x = self.fc2(x)\n","\n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-1lW75dx3q5J","colab_type":"text"},"source":["#네트워크를 저장하거나 불러오는 함수 작성"]},{"cell_type":"code","metadata":{"id":"CZhuvCQD3p1d","colab_type":"code","colab":{}},"source":["def save(ckpt_dir, net, optim, epoch):\n","    if not os.path.exists(ckpt_dir):\n","        os.makedirs(ckpt_dir)\n","\n","    torch.save({'net': net.state_dict(), 'optim': optim.state_dict()},\n","               './%s/model_epoch%d.pth' % (ckpt_dir, epoch))\n","\n","    # print('model_epoch%d.pth is saved.' % epoch)\n","\n","def load(ckpt_dir, net, optim):\n","    if not os.path.exists(ckpt_dir):\n","      epoch = 0\n","      return net, optim, epoch\n","    \n","    ckpt_lst = os.listdir(ckpt_dir)\n","    ckpt_lst.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))\n","\n","    dict_model = torch.load('./%s/%s' % (ckpt_dir, ckpt_lst[-1]))\n","\n","    net.load_state_dict(dict_model['net'])\n","    optim.load_state_dict(dict_model['optim'])\n","    epoch = int(ckpt_lst[-1].split('epoch')[1].split('.pth')[0])\n","\n","    # print('%s is loaded.' % ckpt_lst[-1])\n","\n","    return net, optim, epoch"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IxRJhPFR3wm6","colab_type":"text"},"source":["#학습 데이터 불러오기"]},{"cell_type":"code","metadata":{"id":"-a7dDQQT3u6K","colab_type":"code","colab":{}},"source":["transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=(0.5,), std=(0.5,))])\n","\n","dataset = datasets.MNIST(download=True, root=data_dir, train=True, transform=transform)\n","loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n","\n","num_data = len(loader.dataset)\n","num_batch = round(num_data / batch_size)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lQe4oTXy32Xv","colab_type":"text"},"source":["#네트워크 생성하기"]},{"cell_type":"code","metadata":{"id":"7_r3GA7S30oS","colab_type":"code","colab":{}},"source":["net = Net().to(device)\n","params = net.parameters()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T_jIvf2b39NF","colab_type":"text"},"source":["#손실함수 등을 설정하기"]},{"cell_type":"code","metadata":{"id":"DjAzNVsO38iR","colab_type":"code","colab":{}},"source":["fn_loss = nn.CrossEntropyLoss().to(device)\n","fn_pred = lambda output: torch.softmax(output, dim=1)\n","fn_acc = lambda pred, label: ((pred.max(dim=1)[1] == label).type(torch.float)).mean()\n","\n","optim = torch.optim.Adam(params, lr=lr)\n","\n","writer = SummaryWriter(log_dir=log_dir)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"udi5-K_xEQLd","colab_type":"text"},"source":["#Load the trained network"]},{"cell_type":"code","metadata":{"id":"111cZvtAEPfO","colab_type":"code","colab":{}},"source":["st_epoch = 0\n","net, optim, st_epoch = load(ckpt_dir=ckpt_dir, net=net, optim=optim)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MZkNa8CK4TZo","colab_type":"text"},"source":["#트레이닝 시작하기"]},{"cell_type":"code","metadata":{"id":"t3m_PHNT4Azp","colab_type":"code","outputId":"79d63c89-59d2-48ff-94e8-5fd7bd251a92","executionInfo":{"status":"ok","timestamp":1582062612297,"user_tz":420,"elapsed":105941,"user":{"displayName":"한요섭","photoUrl":"https://lh5.googleusercontent.com/-YFCq7U3ZRkA/AAAAAAAAAAI/AAAAAAAARHc/gXM5cCKzru0/s64/photo.jpg","userId":"13321053678363808287"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["for epoch in range(st_epoch + 1, num_epoch + 1):\n","# for epoch in tqdm_notebook(range(1, num_epoch + 1)):\n","    net.train()\n","\n","    loss_arr = []\n","    acc_arr = []\n","\n","    for batch, (input, label) in enumerate(loader, 1):\n","    # for batch, (input, label) in enumerate(tqdm_notebook(loader), 1):\n","        # forward propagation 하기\n","        input = input.to(device)\n","        label = label.to(device)\n","\n","        output = net(input)\n","        pred = fn_pred(output)\n","\n","        # backward propagation 하기\n","        optim.zero_grad()\n","\n","        loss = fn_loss(output, label)\n","        loss.backward()\n","\n","        acc = fn_acc(pred, label)\n","\n","        optim.step()\n","\n","        # 손실함수를 계산하기\n","        loss_arr += [loss.item()]\n","        acc_arr += [acc.item()]\n","\n","        if batch % num_freq == 0:\n","          print('TRAIN: EPOCH %d/%d | BATCH %04d/%04d | LOSS: %.4f | ACC: %.4f' %\n","                (epoch, num_epoch, batch, num_batch, np.mean(loss_arr), np.mean(acc_arr)))\n","\n","    # log 를 저장하기\n","    writer.add_scalar('loss', np.mean(loss_arr), epoch)\n","    writer.add_scalar('acc', np.mean(acc_arr), epoch)\n","\n","    # 네트워크를 저장하기\n","    save(ckpt_dir=ckpt_dir, net=net, optim=optim, epoch=epoch)\n","\n","writer.close()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["TRAIN: EPOCH 1/10 | BATCH 0100/0938 | LOSS: 0.1373 | ACC: 0.9609\n","TRAIN: EPOCH 1/10 | BATCH 0200/0938 | LOSS: 0.1364 | ACC: 0.9607\n","TRAIN: EPOCH 1/10 | BATCH 0300/0938 | LOSS: 0.1345 | ACC: 0.9604\n","TRAIN: EPOCH 1/10 | BATCH 0400/0938 | LOSS: 0.1379 | ACC: 0.9593\n","TRAIN: EPOCH 1/10 | BATCH 0500/0938 | LOSS: 0.1387 | ACC: 0.9588\n","TRAIN: EPOCH 1/10 | BATCH 0600/0938 | LOSS: 0.1366 | ACC: 0.9592\n","TRAIN: EPOCH 1/10 | BATCH 0700/0938 | LOSS: 0.1375 | ACC: 0.9594\n","TRAIN: EPOCH 1/10 | BATCH 0800/0938 | LOSS: 0.1382 | ACC: 0.9592\n","TRAIN: EPOCH 1/10 | BATCH 0900/0938 | LOSS: 0.1404 | ACC: 0.9591\n","TRAIN: EPOCH 2/10 | BATCH 0100/0938 | LOSS: 0.1295 | ACC: 0.9575\n","TRAIN: EPOCH 2/10 | BATCH 0200/0938 | LOSS: 0.1322 | ACC: 0.9599\n","TRAIN: EPOCH 2/10 | BATCH 0300/0938 | LOSS: 0.1285 | ACC: 0.9605\n","TRAIN: EPOCH 2/10 | BATCH 0400/0938 | LOSS: 0.1280 | ACC: 0.9611\n","TRAIN: EPOCH 2/10 | BATCH 0500/0938 | LOSS: 0.1299 | ACC: 0.9603\n","TRAIN: EPOCH 2/10 | BATCH 0600/0938 | LOSS: 0.1309 | ACC: 0.9605\n","TRAIN: EPOCH 2/10 | BATCH 0700/0938 | LOSS: 0.1328 | ACC: 0.9605\n","TRAIN: EPOCH 2/10 | BATCH 0800/0938 | LOSS: 0.1321 | ACC: 0.9605\n","TRAIN: EPOCH 2/10 | BATCH 0900/0938 | LOSS: 0.1315 | ACC: 0.9608\n","TRAIN: EPOCH 3/10 | BATCH 0100/0938 | LOSS: 0.1156 | ACC: 0.9622\n","TRAIN: EPOCH 3/10 | BATCH 0200/0938 | LOSS: 0.1235 | ACC: 0.9615\n","TRAIN: EPOCH 3/10 | BATCH 0300/0938 | LOSS: 0.1277 | ACC: 0.9604\n","TRAIN: EPOCH 3/10 | BATCH 0400/0938 | LOSS: 0.1287 | ACC: 0.9602\n","TRAIN: EPOCH 3/10 | BATCH 0500/0938 | LOSS: 0.1269 | ACC: 0.9607\n","TRAIN: EPOCH 3/10 | BATCH 0600/0938 | LOSS: 0.1269 | ACC: 0.9613\n","TRAIN: EPOCH 3/10 | BATCH 0700/0938 | LOSS: 0.1272 | ACC: 0.9616\n","TRAIN: EPOCH 3/10 | BATCH 0800/0938 | LOSS: 0.1275 | ACC: 0.9613\n","TRAIN: EPOCH 3/10 | BATCH 0900/0938 | LOSS: 0.1266 | ACC: 0.9615\n","TRAIN: EPOCH 4/10 | BATCH 0100/0938 | LOSS: 0.1343 | ACC: 0.9594\n","TRAIN: EPOCH 4/10 | BATCH 0200/0938 | LOSS: 0.1347 | ACC: 0.9604\n","TRAIN: EPOCH 4/10 | BATCH 0300/0938 | LOSS: 0.1333 | ACC: 0.9604\n","TRAIN: EPOCH 4/10 | BATCH 0400/0938 | LOSS: 0.1330 | ACC: 0.9610\n","TRAIN: EPOCH 4/10 | BATCH 0500/0938 | LOSS: 0.1303 | ACC: 0.9618\n","TRAIN: EPOCH 4/10 | BATCH 0600/0938 | LOSS: 0.1284 | ACC: 0.9617\n","TRAIN: EPOCH 4/10 | BATCH 0700/0938 | LOSS: 0.1299 | ACC: 0.9609\n","TRAIN: EPOCH 4/10 | BATCH 0800/0938 | LOSS: 0.1285 | ACC: 0.9609\n","TRAIN: EPOCH 4/10 | BATCH 0900/0938 | LOSS: 0.1280 | ACC: 0.9612\n","TRAIN: EPOCH 5/10 | BATCH 0100/0938 | LOSS: 0.1197 | ACC: 0.9625\n","TRAIN: EPOCH 5/10 | BATCH 0200/0938 | LOSS: 0.1148 | ACC: 0.9660\n","TRAIN: EPOCH 5/10 | BATCH 0300/0938 | LOSS: 0.1201 | ACC: 0.9644\n","TRAIN: EPOCH 5/10 | BATCH 0400/0938 | LOSS: 0.1191 | ACC: 0.9639\n","TRAIN: EPOCH 5/10 | BATCH 0500/0938 | LOSS: 0.1210 | ACC: 0.9634\n","TRAIN: EPOCH 5/10 | BATCH 0600/0938 | LOSS: 0.1214 | ACC: 0.9635\n","TRAIN: EPOCH 5/10 | BATCH 0700/0938 | LOSS: 0.1223 | ACC: 0.9631\n","TRAIN: EPOCH 5/10 | BATCH 0800/0938 | LOSS: 0.1233 | ACC: 0.9627\n","TRAIN: EPOCH 5/10 | BATCH 0900/0938 | LOSS: 0.1226 | ACC: 0.9630\n","TRAIN: EPOCH 6/10 | BATCH 0100/0938 | LOSS: 0.1235 | ACC: 0.9609\n","TRAIN: EPOCH 6/10 | BATCH 0200/0938 | LOSS: 0.1278 | ACC: 0.9622\n","TRAIN: EPOCH 6/10 | BATCH 0300/0938 | LOSS: 0.1293 | ACC: 0.9626\n","TRAIN: EPOCH 6/10 | BATCH 0400/0938 | LOSS: 0.1280 | ACC: 0.9627\n","TRAIN: EPOCH 6/10 | BATCH 0500/0938 | LOSS: 0.1263 | ACC: 0.9630\n","TRAIN: EPOCH 6/10 | BATCH 0600/0938 | LOSS: 0.1264 | ACC: 0.9624\n","TRAIN: EPOCH 6/10 | BATCH 0700/0938 | LOSS: 0.1240 | ACC: 0.9626\n","TRAIN: EPOCH 6/10 | BATCH 0800/0938 | LOSS: 0.1233 | ACC: 0.9628\n","TRAIN: EPOCH 6/10 | BATCH 0900/0938 | LOSS: 0.1225 | ACC: 0.9631\n","TRAIN: EPOCH 7/10 | BATCH 0100/0938 | LOSS: 0.1161 | ACC: 0.9644\n","TRAIN: EPOCH 7/10 | BATCH 0200/0938 | LOSS: 0.1203 | ACC: 0.9623\n","TRAIN: EPOCH 7/10 | BATCH 0300/0938 | LOSS: 0.1184 | ACC: 0.9629\n","TRAIN: EPOCH 7/10 | BATCH 0400/0938 | LOSS: 0.1190 | ACC: 0.9632\n","TRAIN: EPOCH 7/10 | BATCH 0500/0938 | LOSS: 0.1185 | ACC: 0.9640\n","TRAIN: EPOCH 7/10 | BATCH 0600/0938 | LOSS: 0.1158 | ACC: 0.9651\n","TRAIN: EPOCH 7/10 | BATCH 0700/0938 | LOSS: 0.1178 | ACC: 0.9646\n","TRAIN: EPOCH 7/10 | BATCH 0800/0938 | LOSS: 0.1170 | ACC: 0.9648\n","TRAIN: EPOCH 7/10 | BATCH 0900/0938 | LOSS: 0.1171 | ACC: 0.9646\n","TRAIN: EPOCH 8/10 | BATCH 0100/0938 | LOSS: 0.1152 | ACC: 0.9627\n","TRAIN: EPOCH 8/10 | BATCH 0200/0938 | LOSS: 0.1113 | ACC: 0.9657\n","TRAIN: EPOCH 8/10 | BATCH 0300/0938 | LOSS: 0.1162 | ACC: 0.9638\n","TRAIN: EPOCH 8/10 | BATCH 0400/0938 | LOSS: 0.1208 | ACC: 0.9625\n","TRAIN: EPOCH 8/10 | BATCH 0500/0938 | LOSS: 0.1207 | ACC: 0.9637\n","TRAIN: EPOCH 8/10 | BATCH 0600/0938 | LOSS: 0.1224 | ACC: 0.9632\n","TRAIN: EPOCH 8/10 | BATCH 0700/0938 | LOSS: 0.1209 | ACC: 0.9637\n","TRAIN: EPOCH 8/10 | BATCH 0800/0938 | LOSS: 0.1196 | ACC: 0.9640\n","TRAIN: EPOCH 8/10 | BATCH 0900/0938 | LOSS: 0.1196 | ACC: 0.9640\n","TRAIN: EPOCH 9/10 | BATCH 0100/0938 | LOSS: 0.1152 | ACC: 0.9659\n","TRAIN: EPOCH 9/10 | BATCH 0200/0938 | LOSS: 0.1141 | ACC: 0.9665\n","TRAIN: EPOCH 9/10 | BATCH 0300/0938 | LOSS: 0.1163 | ACC: 0.9653\n","TRAIN: EPOCH 9/10 | BATCH 0400/0938 | LOSS: 0.1154 | ACC: 0.9660\n","TRAIN: EPOCH 9/10 | BATCH 0500/0938 | LOSS: 0.1171 | ACC: 0.9655\n","TRAIN: EPOCH 9/10 | BATCH 0600/0938 | LOSS: 0.1137 | ACC: 0.9666\n","TRAIN: EPOCH 9/10 | BATCH 0700/0938 | LOSS: 0.1156 | ACC: 0.9654\n","TRAIN: EPOCH 9/10 | BATCH 0800/0938 | LOSS: 0.1147 | ACC: 0.9655\n","TRAIN: EPOCH 9/10 | BATCH 0900/0938 | LOSS: 0.1159 | ACC: 0.9652\n","TRAIN: EPOCH 10/10 | BATCH 0100/0938 | LOSS: 0.1191 | ACC: 0.9648\n","TRAIN: EPOCH 10/10 | BATCH 0200/0938 | LOSS: 0.1156 | ACC: 0.9644\n","TRAIN: EPOCH 10/10 | BATCH 0300/0938 | LOSS: 0.1124 | ACC: 0.9655\n","TRAIN: EPOCH 10/10 | BATCH 0400/0938 | LOSS: 0.1117 | ACC: 0.9661\n","TRAIN: EPOCH 10/10 | BATCH 0500/0938 | LOSS: 0.1110 | ACC: 0.9663\n","TRAIN: EPOCH 10/10 | BATCH 0600/0938 | LOSS: 0.1083 | ACC: 0.9666\n","TRAIN: EPOCH 10/10 | BATCH 0700/0938 | LOSS: 0.1108 | ACC: 0.9658\n","TRAIN: EPOCH 10/10 | BATCH 0800/0938 | LOSS: 0.1100 | ACC: 0.9659\n","TRAIN: EPOCH 10/10 | BATCH 0900/0938 | LOSS: 0.1107 | ACC: 0.9658\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7Q2_k3Jl__oz","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}